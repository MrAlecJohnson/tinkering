{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "from time import time\n",
    "\n",
    "from gensim.models.doc2vec import TaggedDocument, Doc2Vec\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "df = pd.read_excel(Path.cwd().parent / \"export-2022-01-06-11-48-21.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into three sets of columns - demographics, question answers, irrelevancies\n",
    "question_indexes = sorted(\n",
    "    [i for i, q in enumerate(df.columns) if \"question\" in q.lower()]\n",
    ")\n",
    "first, last = min(question_indexes), max(question_indexes)\n",
    "\n",
    "demographics = df.iloc[:, :first]\n",
    "questions = df.iloc[:, first : last + 1]\n",
    "not_needed = df.iloc[:, last + 1 :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are 66 columns in the questions section, but 3 are followups to categorical questions\n",
    "print(len(questions.columns))\n",
    "followups = [\n",
    "    q for q in questions.columns if q.lower().endswith(\"please explain your answer:\")\n",
    "]\n",
    "print(len(followups))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Work out which questions we could treat as categorical yes/no if we wanted\n",
    "# There are 21 (after removing one that's in 2 parts)\n",
    "binary_starts = (\"do\", \"should\", \"could\", \"are there\", \"would\", \"is more\", \"have we\")\n",
    "binary_questions = [q for q in questions.columns if q.lower().startswith(binary_starts)]\n",
    "print(len(binary_questions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick test run of setting up a corpus and building word2vec on it\n",
    "texts = []\n",
    "for col in questions.columns:\n",
    "    texts.extend(questions[col][questions[col].notnull()].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimal preprocessing as a starting point\n",
    "def preprocess(text: str) -> str:\n",
    "    # This removes punctuation, though arguably that's not a great idea\n",
    "    return [w.lower() for w in word_tokenize(str(text)) if w.isalpha()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build doc2vec\n",
    "processed = list(map(preprocess, texts))\n",
    "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(processed)]\n",
    "\n",
    "start = time()\n",
    "model = Doc2Vec(documents, vector_size=100, window=4, min_count=2, seed=100)\n",
    "print(time() - start)\n",
    "print(f\"Vocab size = {len(model.wv)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do a similarity search. But results pretty crummy.\n",
    "# Partly minute amount of data, but doesn't even find docs that contain the search term\n",
    "def search(query, model, documents, topn=5, print_results=True):\n",
    "    processed_query = preprocess(query)\n",
    "    vectorised_query = model.infer_vector(processed_query)\n",
    "    closest_matches = model.dv.most_similar([vectorised_query], topn=topn)\n",
    "    results = [\n",
    "        {\"key\": match[0], \"similarity\": match[1], \"text\": documents[match[0]][0]}\n",
    "        for match in closest_matches\n",
    "    ]\n",
    "\n",
    "    if print_results:\n",
    "        print(f\"Search query: '{query}'\")\n",
    "        for i, r in enumerate(results):\n",
    "            print(f\"Rank {i}, similarity {r['similarity']}\")\n",
    "            print(f\"Document: {' '.join(r['text'])}\", end=\"\\n\\n\")\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "_ = search(\"Domestic abuse\", model, documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if I do sentences instead of docs?\n",
    "sentences = []\n",
    "for col in questions.columns:\n",
    "    answers = questions[col][questions[col].notnull()].tolist()\n",
    "    for answer in answers:\n",
    "        sentences.extend(sent_tokenize(str(answer)))\n",
    "\n",
    "# Build doc2vec\n",
    "processed = list(map(preprocess, sentences))\n",
    "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(processed)]\n",
    "\n",
    "start = time()\n",
    "model = Doc2Vec(documents, vector_size=100, window=4, min_count=2, seed=100)\n",
    "print(time() - start)\n",
    "print(f\"Vocab size = {len(model.wv)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search again. Results are the same - people write in very long sentences!\n",
    "_ = search(\"Domestic abuse\", model, documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should do the sanity check code from the Gensim tutorials\n",
    "# This checks each doc is most similar to itself\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f55019471d8c7990b4811b8d274212ff300a811828c03b53e2c14451c3d668a7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('tinkering': pyenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
